# # # from office365.runtime.auth.user_credential import UserCredential
# # # from office365.sharepoint.client_context import ClientContext
# # # site_url = "https://bgsips.sharepoint.com"
# # # ctx = ClientContext(site_url).with_credentials(UserCredential("vaibhav.1999@bgsips.in", "Dwarka21luck"))
# # # web = ctx.web
# # # ctx.load(web)
# # # ctx.execute_query()
# # # print("Web title: {0}".format(web.properties['Title']))
# # import requests
# # import json
# prompt = """
# Data - 

# Please make a note of RFS number in any email exchange.Need to have soft copy.


# Check with Kat for above.
# Can you please follow up with above projects for billing

# 627-Siva-Crowd- ISSUE
# Maros





# Ongoing Issues :
# 10 Aug :
# Hi Nanda –634- for the physical destruction of Eupnsudcdb050 mentioned below, we discussed and agreed an approach 2 weeks ago yet it is still TBD, how comes?
# s per DC Team, the data destruction will take 4 Months to complete including Certificate issue. Nanda will look if OS level something can be done.Mohinder will check if there is any contact point(CPE)wait till 20 Aug.4 months timeline.Rohit has done something like this in past.This is not mentioned explicitly in PWO.wait for 10 days because Tech resource is on leave else agree with Chris that we can leave that and complete the SoW.This is not chargeable activity.support at management level.




# Are we ok to line up a Kyndryl SME for this morning to help troubleshoot? I’m ok with covering the costs using APE0582 for the SAN Switch SME’s time this morning.

# Nanda OSIM team
# the same time as described below. Up to 4 months.
# This is only an emergency solution. Not the normal process.
# Since the account is responsible for deleting the HDDs before the machines are unplugged and removed



# Nanda -634 -4 months from datacenter..keep them also it requires 8k-9k
 
# In a nut shell we need to know if there are any other ways to destroy the cards and share certificate with Astellas without going the whole degaussing process as the process is currently taking too long.Data center team.UKI leadership. Holding the revenue.
# 8000 to 9000 usd to keep them.

# Nexus SIEM agent points
# Just so  we are on the same page.
# 1.Rohit will share the Documents (PWO ) so the legal angle can be looked at.
# 2.We can propose Ansible Automation but not for ESXi hosts.
# 3.To give the Proper estimates for the entire work we need to do some analysis and meeting with technical team
# 4.We have next meeting with Chris on tuesday.
# 5.In case we agree to do it has to be a 0 value PCR so we have a defined scope.
# 6.As of now roughly there are 40 servers +20 ESXi hosts(EMEA only) that Chris is mentioning.




 
# michael.berndt@kyndryl.com(this is kyndryl person)?
# ddmteam@kyndryl.com


# Ask mohinder about the degaussing certificate. It is taking too much time.Alfred is not replying ,
# Give a headsup to Graham about NEXUS one.open ended one.(deb and Rohit ) nothing was agreed.Have a discussion with Arif 

# Action  MIRA tool

# Ask Rohit bout status of 589


# 2013 mpp without License…Shashi
# Quality team delays-->Graham
# 573 budget 
# Graham --> for Nexus case-->573--Rohit said there is a list of servers in that.
# 622 ask Natasha
# Ask maros Lenka is on leave so what  is the PO number ?
# APE0630 - Chanchal/Rohit--Decommission Wave 2A M4 -  $18,151 [We are expecting the Degaussing Certificate by July end. Might be pushed to next month]
# Kalpna- claim code was not working .
# Rohit keep a meeting with 589..server analysis will be done?
# APE0582 - Approval for invoicing July'22

# Implementation Phase of APE0453 Phase 2 - Hillswood Site Move (Execution)-Nanda
# Implementation Phase of APE0453 Phase 2 - PCR001 - Project Home Implementation -Nanda
# Implementation Phase of APE0639- Kyndryl Decommission of Empower 3-Siva
# Implementation Phase of APE0638 Phase 1 - eu.astellas.net Domain Decommission  -


# See kats point on RFS board meeting

# Actions on Chris :
# See the Delivery Report in Green
# 627 Siva why are you asking to  descope this.


# APE0622 :-
# QM, Natasza  needs to share the Every Angle operation Manual ( OM )  in the latest template and also , she needs to follow up with Caitriona for approval of LIMS Citrix Manual OM


# RFS Board meeting- point of Degaussing Certifcate .Why it takes so much time.
# 573

# CHG0117341 did not align in terms of CI names with the CIs listed in the change in ServiceNow. Difference in name
# Present and selected in SNOW as affected CI:
# 634-natasha raised issue on this.



# 2nd August
# APE0622 :-
# QM, Natasza  needs to share the Every Angle operation Manual ( OM )  in the latest template and also , she needs to follow up with Caitriona for approval of LIMS Citrix Manual OM



# Kalpana issue-hands and eyes and CRT approval.
# Lekhni,whatsapp and PMs groups id.
# Keeping the call at 1:30
# What about 639,LOA and mail (PO number from Lenka)

# How do PMs claim-ask Deb.

# 1. APE0613 - Transfer of ATT Switches to Astellas M1 - $2,627   [This is with Michael Smith. No confirmation on this yet]
# 2. APE0630 - Chanchal/Rohit--Decommission Wave 2A M4 -  $18,151 [We are expecting the Degaussing Certificate by July end. Might be pushed to next month]
# 3. APE0639 -Siva-  Kyndryl Decommission of Empower 3 M1 -  $7,380 [ Should be completed by July end]
# 4. APE0642 - Chanchal/rohit Kyndryl Global Decommission Wave A M1 -  $6,130 [All changes task completed successfully, and QM is reviewing Evidences for Change closure.Should be completed by July end or August first week  ]--some agreement with Chris.



# On point #5, this may take more than a month however please ensure point #4 I progressed and completed if it doesn’t have dependency.
# 4. FSR request has been raised by me to reserve Rack space allocation, on Monday – 25th July. Hemanth is working on that.
# 5.Server Boarding Service (SBS) request has to be raised next, but we were blocked, because there is no design document ready -Srinath told that it will take some time to get it ready. This has dependencies with Systal team he mentioned. 

# Deepika case :

# GRE tunnel was with Rohit.




# Team channel Astellas team. This Networking meeting is for what?
# GRE Tunnel
# Avinash -Solaris server Decom project.
# Anything I missed in yesterday's call.
# Hardcopy documentation can be securely destroyed- 642-Chanchal/Rohit.everything is completed.compliance team close it in tool.
# APE0573 - Kalpana- Kat was asking about the budget extension for this?-



# Shashi said :As part of Astellas account, we have procured the following Cisco devices ( attached sheet with details) . We received confirmation that last four devices are received by  Geodis in EMEA . But we could not locate or track the remaining devices . So please can you review the list and let us if you have any information of these devices else direct us to team who can help us with the details
 
# Once we track all these devices, we will share the location details ( DCO/DCS in Frankfurt ) where these devices need to be transported. 
# Cisco Project :
# Arno is not at Geodis location.You need to get this delivered to datacenter.


# -COMPLETEDTASKS***********************************************************************************************************************************



# 25 July(July billing)
# 630 -rohit-degaussing certificate- 
# 639-shiva- will this be completed in July
# 642-Rohit- Confirm whether this can be done.
# PO number just ping Lenka.

# 613 -Attached is the AT&T Countersigned contract for SWITZERLAND and I am re-sending AUSTRIA, so we have one email with both signed agreements and matches the email title .
# Hi – as discussed – re-sale agreements signed and completed,
# So for these do we have any actions deb. No closure report needed ..right?

# What is GP% for Astellas -this is 60%

# Rohit -Summary Sheet? But 589 PCR. What should be done.

# What are we with 627 (crowdstrike one)-Shiva.

# APE0xxx (budget extension PWO to APE0573) - EMEA Nexus Transformation Assistance -Kat sent this
# In the plan Astellas (EMEA) RFS Status Board

# Astellas Starters and Leavers <ASTSL@kyndryl.com>"""
# # url = "http://localhost:3000/conversation"

# # payload = {
# #     "message":  prompt
# #     # "conversationId": "your-conversation-id (optional)",
# #     # "parentMessageId": "your-parent-message-id (optional)"
# # }

# # headers = {
# #     'Content-Type': "application/json"
# #     # 'cache-control': "no-cache",
# #     # 'Postman-Token': "c8f9f9f0-f9f9-f9f9-f9f9-f9f9f9f9f9f9"
# #     }

# # response = requests.request("POST", url, data=json.dumps(payload), headers=headers)
# # print(response.json())
# # print(response.json()["response"])
# import openai
# import concurrent.futures
# datelist = []
# from revChatGPT.Official import Chatbot
# "You are a portfolio manager.I will give you some mixed data regarding the projects I manage. Separate the data in terms of the project it refers to.Eg-Put ALL the data regarding or related to a project AEW66 under the project.All Data must be categorised under a project or a heading."
# defaultModel = "text-chat-davinci-002-XXXXXXXX"
# successfulModels = []
# st.secrets["db_username"]
# def test_model(model):
#     try:
#         bot = Chatbot(api_key="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",model=model)
#         for response in bot.ask_stream("Hi"):
#             print(response, end="")
            
#         if response:
#             successfulModels.append(model)
#         return response

#     except Exception as e:
#         print(e)
#         print("Model [" + model + "] failed to load. (Invalid Request Error)")

# # with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
# #     for year in range(2022, 2023):
# #         for month in range(1, 13):
# #             for day in range(1, 32):
# #                 formatted_year = "{:04d}".format(year)
# #                 formatted_month = "{:02d}".format(month)
# #                 formatted_day = "{:02d}".format(day)
# #                 datelist.append(formatted_year + formatted_month + formatted_day)
# #                 model = defaultModel.replace("XXXXXXXX", formatted_year + formatted_month + formatted_day)
# #                 executor.submit(test_model, model)
# test_model('text-chat-davinci-002-20221122')
# # print(datelist)
# # print("Successful Models: " + str(successfulModels))
import csv
csvFilePath = r"C:\Users\vaibhavarduino\Downloads\prompts.csv"
jsonFilePath = r"C:\Users\vaibhavarduino\Downloads\prompts.json"
input_file = csv.DictReader(open(csvFilePath))
from memory.memory import Memory
m = Memory()
promptdict = {}
for row in input_file:
    row = {row['act']:row['prompt']}
    promptdict= {**promptdict, **row}
keysList = list(promptdict.keys())
print(keysList)
m.update_data("PROMPTS",promptdict)
m.save()

# print(promptdict['Product Manager'])
